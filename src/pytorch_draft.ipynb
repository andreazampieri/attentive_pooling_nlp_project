{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_draft.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "r26WdfN-wtwz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "outputId": "01118c0c-c310-416e-c57f-18eb4e7e5b5d"
      },
      "cell_type": "code",
      "source": [
        "!pip install torch torchtext torchvision\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 32kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x584de000 @  0x7ff8b47d81c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "\u001b[?25hCollecting torchtext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/90/474d5944d43001a6e72b9aaed5c3e4f77516fbef2317002da2096fd8b5ea/torchtext-0.2.3.tar.gz (42kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 13.6MB/s \n",
            "\u001b[?25hCollecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 22.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.26.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.18.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2018.8.24)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.22)\n",
            "Building wheels for collected packages: torchtext\n",
            "  Running setup.py bdist_wheel for torchtext ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/42/a6/f4/b267328bde6bb680094a0c173e8e5627ccc99543abded97204\n",
            "Successfully built torchtext\n",
            "Installing collected packages: torch, torchtext, pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.3.0 torch-0.4.1 torchtext-0.2.3 torchvision-0.2.1\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EPB7hxUWmLEU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as f\n",
        "from torch.autograd import Variable\n",
        "from torchtext.vocab import GloVe\n",
        "from torchtext import data\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r-PBzD9QrA0f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class WikiQA_dataset():\n",
        "  def __init__(self,base_dir,embedding_dim,batch_size):\n",
        "    self.RAW = data.RawField()\n",
        "    self.TEXT = data.Field(batch_first=True,\n",
        "                           lower=True)\n",
        "    self.LABEL = data.Field(sequential=False,\n",
        "                            unk_token=None)\n",
        "\n",
        "\n",
        "    self.train, self.dev, self.test = data.TabularDataset.splits(\n",
        "        path=base_dir,\n",
        "        train='WikiQA-train.tsv',\n",
        "        validation='WikiQA-dev.tsv',\n",
        "        test='WikiQA-test.tsv',\n",
        "        format='tsv',\n",
        "        fields=[('qid', self.RAW),\n",
        "                ('question', self.TEXT),\n",
        "                ('docid', self.RAW),\n",
        "                ('doctitle', self.RAW),\n",
        "                ('sentenceid',self.RAW),\n",
        "                ('sentence',self.TEXT),\n",
        "                ('label',self.LABEL)])\n",
        "\n",
        "    self.TEXT.build_vocab(self.train, self.dev, self.test, \\\n",
        "                          vectors=GloVe(name='6B', dim=embedding_dim), \\\n",
        "                          unk_init=torch.zeros((1, embedding_dim)).uniform_(-0.25, 0.25))\n",
        "\n",
        "    self.LABEL.build_vocab(self.train)\n",
        "\n",
        "    self.train_iter, self.dev_iter, self.test_iter = \\\n",
        "        data.Iterator.splits((self.train, self.dev, self.test),\n",
        "                             batch_sizes=[batch_size] * 3,\n",
        "                             shuffle=True,\n",
        "                             sort_key=lambda x: data.interleave_keys(0, 0))\n",
        "    \n",
        "class InsuranceQA_dataset():\n",
        "  \n",
        "  def __init__(self,base_dir,embedding_dim,batch_size,use_tokenized=True):\n",
        "    self.RAW = data.RawField()\n",
        "    self.TEXT = data.Field(batch_first=True,\n",
        "                           lower=True)\n",
        "    self.LABEL = data.Field(sequential=False,\n",
        "                            unk_token=None)\n",
        "    \n",
        "    prefix = 'token' if use_tokenized else 'raw'\n",
        "\n",
        "    self.train, self.dev, self.test = data.TabularDataset.splits(\n",
        "        path=base_dir,\n",
        "        train= prefix+'train.tsv',\n",
        "        validation= prefix+'valid.tsv',\n",
        "        test= prefix+'test.tsv',\n",
        "        format='tsv',\n",
        "        fields=[('question', self.TEXT),\n",
        "                ('sentence',self.TEXT),\n",
        "                ('label',self.LABEL)])\n",
        "\n",
        "    self.TEXT.build_vocab(self.train, self.dev, self.test, \\\n",
        "                          vectors=GloVe(name='6B', dim=embedding_dim), \\\n",
        "                          unk_init=torch.zeros((1, embedding_dim)).uniform_(-0.25, 0.25))\n",
        "\n",
        "    self.LABEL.build_vocab(self.train)\n",
        "\n",
        "    self.train_iter, self.dev_iter, self.test_iter = \\\n",
        "        data.Iterator.splits((self.train, self.dev, self.test),\n",
        "                             batch_sizes=[batch_size] * 3,\n",
        "                             shuffle=True,\n",
        "                             sort_key=lambda x: data.interleave_keys(0, 0))\n",
        "    \n",
        "class GloVeEmb(nn.Module):\n",
        "  \n",
        "  def __init__(self,emb_dim,dict_size,data,trainable=True):\n",
        "    super(GloVeEmb,self).__init__()\n",
        "    self.emb = nn.Embedding(dict_size,emb_dim)\n",
        "    self.emb.weight.data.copy_(data.TEXT.vocab.vectors)\n",
        "    self.emb.weight.requires_grad = trainable\n",
        "    \n",
        "  def forward(self,x):\n",
        "    return self.emb(x)\n",
        "    \n",
        "class ConvolutionModule(nn.Module):\n",
        "  \n",
        "  def __init__(self,emb_dim,dict_size,hidden_dim,ctx_window):\n",
        "    super(ConvolutionModule,self).__init__()\n",
        "    self.conv = nn.Conv2d(1,hidden_dim,kernel_size=(ctx_window,emb_dim))\n",
        "    odd_adjustment = 1 if ctx_window%2==0 else 0\n",
        "    self.pad = nn.ZeroPad2d((0,0,ctx_window-1-odd_adjustment,ctx_window-1))\n",
        "    \n",
        "  def forward(self,x_emb):\n",
        "    x_emb = x_emb.unsqueeze(1) #adding a dimension (the channel for the convolution)   \n",
        "    return f.relu(self.conv(self.pad(x_emb))).squeeze(dim=3) # remove the single channel extra dimension\n",
        "\n",
        "  \n",
        "class BaselineQACNN(nn.Module):\n",
        "  \n",
        "  def __init__(self,emb_dim,dict_size,hidden_dim,ctx_window,data,decision_threshold=0.5):\n",
        "    super(BaselineQACNN,self).__init__()\n",
        "    self.emb = GloVeEmb(emb_dim,dict_size,data)\n",
        "    self.convolution_q = ConvolutionModule(emb_dim,dict_size,hidden_dim,ctx_window)\n",
        "    self.convolution_a = ConvolutionModule(emb_dim,dict_size,hidden_dim,ctx_window)\n",
        "    self.h_pool = lambda t : self.horizontal_pooling(t)\n",
        "    self.crit = nn.CosineEmbeddingLoss(margin=0.5)\n",
        "    self.decision_threshold = decision_threshold\n",
        "    self.tostring = {\"name\":\"base_cnn\",\"emb_dim\":emb_dim,\"hidden_dim\":hidden_dim,\"ctx_window\":ctx_window}\n",
        "    \n",
        "  def forward(self,q,a):\n",
        "    q_embed = self.emb(q)\n",
        "    a_embed = self.emb(a)\n",
        "    q_enc = self.convolution_q(q_embed)\n",
        "    a_enc = self.convolution_a(a_embed)\n",
        "    r_q = self.h_pool(q_enc)\n",
        "    r_a = self.h_pool(a_enc)\n",
        "    return r_q,r_a\n",
        "  \n",
        "  # given a matrix, does a maxpool operation on the rows\n",
        "  # t.view(t.size(0),-1) = flatten into a 1D tensor each outcome for each input sample\n",
        "  # passing from (n,a,b) to (n,a) dimensions\n",
        "  # REVIEW squeeze the last dimension (just one channel); .squeeze() will break training with batch_size=1\n",
        "  def horizontal_pooling(self,t):\n",
        "    return f.max_pool1d(t,t.size(2)).view(t.size(0),-1)\n",
        "  \n",
        "  def compute_batch_stats(self,model_output,batch):\n",
        "    r_q,r_a = model_output    \n",
        "    batch_loss = self.crit(r_q,r_a,batch.label.float()*2.0-1) # the loss wants -1|1 values, input values are 0|1\n",
        "    sim = f.cosine_similarity(r_q,r_a)\n",
        "    # compute the decision of the network\n",
        "    pred = sim.clone()\n",
        "    pred[sim > self.decision_threshold] = 1\n",
        "    pred[sim <= self.decision_threshold] = 0\n",
        "    correct_pred = (pred.squeeze() == batch.label.float()).sum().float()\n",
        "    return sim,batch_loss,correct_pred\n",
        "  \n",
        "  \n",
        "class LSTMModule(nn.Module):\n",
        "  \n",
        "  def __init__(self,emb_dim,single_hidden_dim):\n",
        "    super(LSTMModule,self).__init__()\n",
        "    self.bilstm = nn.LSTM(emb_dim,single_hidden_dim,bidirectional=True)\n",
        "    \n",
        "  def forward(self,x_embed):\n",
        "    # LSTM returns a tuple, the tensor is the first element\n",
        "    return self.bilstm(x_embed)[0]\n",
        "  \n",
        "\n",
        "class BaselineQAbiLSTM(nn.Module):\n",
        "  \n",
        "  def __init__(self,emb_dim,dict_size,single_hidden_dim,data,decision_threshold=0.5):\n",
        "    super(BaselineQAbiLSTM,self).__init__()\n",
        "    self.emb = GloVeEmb(emb_dim,dict_size,data)\n",
        "    self.bilstm_q = LSTMModule(emb_dim,single_hidden_dim)\n",
        "    self.bilstm_a = LSTMModule(emb_dim,single_hidden_dim)\n",
        "    self.h_pool = lambda t : self.horizontal_pooling(t)\n",
        "    self.crit = nn.CosineEmbeddingLoss(margin=0.5)\n",
        "    self.decision_threshold = decision_threshold\n",
        "    self.tostring = {\"name\":\"base_lstm\",\"emb_dim\":emb_dim,\"hidden_dim\":single_hidden_dim*2}\n",
        "    \n",
        "  def forward(self,q,a):\n",
        "    q_embed = self.emb(q)\n",
        "    a_embed = self.emb(a)\n",
        "    q_enc = self.bilstm_q(q_embed)\n",
        "    a_enc = self.bilstm_a(a_embed)\n",
        "    r_q = self.h_pool(q_enc)\n",
        "    r_a = self.h_pool(a_enc)\n",
        "    return r_q,r_a\n",
        "  \n",
        "  # given a matrix, does a maxpool operation on the rows\n",
        "  # t.view(t.size(0),-1) = flatten into a 1D tensor each outcome for each input sample\n",
        "  # passing from (n,a,b) to (n,a) dimensions\n",
        "  # (n_samples,num_words,emb_size)\n",
        "  def horizontal_pooling(self,t):\n",
        "    return f.max_pool1d(t.transpose(1,2),t.size(1)).view(t.size(0),-1)\n",
        "  \n",
        "  def compute_batch_stats(self,model_output,batch):\n",
        "    r_q,r_a = model_output    \n",
        "    batch_loss = self.crit(r_q,r_a,batch.label.float()*2.0-1) # the loss wants -1|1 values, input values are 0|1\n",
        "    sim = f.cosine_similarity(r_q,r_a)\n",
        "    # compute the decision of the network\n",
        "    pred = sim.clone()\n",
        "    pred[sim > self.decision_threshold] = 1\n",
        "    pred[sim <= self.decision_threshold] = 0\n",
        "    correct_pred = (pred.squeeze() == batch.label.float()).sum().float()\n",
        "    return sim,batch_loss,correct_pred\n",
        "  \n",
        "  \n",
        "class AttentionMatrix(nn.Module):\n",
        "  \n",
        "  def __init__(self,emb_dim):\n",
        "    super(AttentionMatrix,self).__init__()\n",
        "    #self.u = nn.Parameter(torch.Tensor(emb_dim,emb_dim).type(torch.FloatTensor),requires_grad=True)\n",
        "    self.u = nn.Parameter(torch.from_numpy(np.random.normal(size=(emb_dim,emb_dim))).type(torch.FloatTensor),requires_grad=True)\n",
        "    \n",
        "  def forward(self,q,a):\n",
        "    qt = q.transpose(1,2)\n",
        "    out = torch.matmul(torch.matmul(qt,self.u),a) # Qt*U*A\n",
        "    return torch.tanh(out)\n",
        "\n",
        "class AP_CNN(nn.Module):\n",
        "  \n",
        "  def __init__(self,emb_dim,dict_size,hidden_dim,ctx_window,data,decision_threshold=0.5):\n",
        "    super(AP_CNN,self).__init__()\n",
        "    self.emb = GloVeEmb(emb_dim,dict_size,data)\n",
        "    self.convolution_q = ConvolutionModule(emb_dim,dict_size,hidden_dim,ctx_window)\n",
        "    self.convolution_a = ConvolutionModule(emb_dim,dict_size,hidden_dim,ctx_window)\n",
        "    self.attention_mat = AttentionMatrix(hidden_dim)\n",
        "    self.h_pool = lambda t : self.horizontal_pooling(t)\n",
        "    self.v_pool = lambda t : self.vertical_pooling(t)\n",
        "    self.crit = nn.CosineEmbeddingLoss(margin=0.5)\n",
        "    self.decision_threshold = decision_threshold\n",
        "    self.tostring = {\"name\":\"ap_cnn\",\"emb_dim\":emb_dim,\"hidden_dim\":hidden_dim,\"ctx_window\":ctx_window}\n",
        "    \n",
        "  def flatten(self,x):\n",
        "    return x.view(x.size(0),-1)\n",
        "    \n",
        "  def forward(self,q,a):\n",
        "    q_emb = self.emb(q)\n",
        "    a_emb = self.emb(a)\n",
        "    q_enc = self.convolution_q(q_emb)\n",
        "    a_enc = self.convolution_a(a_emb)\n",
        "    mat = self.attention_mat(q_enc,a_enc) # check dimensions\n",
        "    q_att = f.softmax(self.h_pool(mat),dim=1)\n",
        "    a_att = f.softmax(self.v_pool(mat),dim=1)\n",
        "    q = self.flatten(torch.matmul(q_enc,q_att))\n",
        "    a = self.flatten(torch.matmul(a_enc,a_att))\n",
        "    return q,a\n",
        "  \n",
        "  def horizontal_pooling(self,x):\n",
        "    return f.max_pool1d(x,x.size(2))\n",
        "  \n",
        "  def vertical_pooling(self,x):\n",
        "    return self.horizontal_pooling(x.transpose(1,2)) \n",
        "    \n",
        "  def compute_batch_stats(self,model_output,batch): # TO BE fixed\n",
        "    r_q,r_a = model_output\n",
        "    batch_loss = self.crit(r_q,r_a,batch.label.float()*2.0-1) # the loss wants -1|1 values, input values are 0|1\n",
        "    sim = f.cosine_similarity(r_q,r_a)\n",
        "    # compute the decision of the network\n",
        "    pred = sim.clone()\n",
        "    pred[sim > self.decision_threshold] = 1\n",
        "    pred[sim <= self.decision_threshold] = 0\n",
        "    correct_pred = (pred.squeeze() == batch.label.float()).sum().float()\n",
        "    return sim,batch_loss,correct_pred\n",
        "\n",
        "  \n",
        "class AP_biLSTM(nn.Module):\n",
        "  \n",
        "  def __init__(self,emb_dim,dict_size,single_hidden_dim,data,decision_threshold=0.5):\n",
        "    super(AP_biLSTM,self).__init__()\n",
        "    self.emb = GloVeEmb(emb_dim,dict_size,data)\n",
        "    self.bilstm_q = LSTMModule(emb_dim,single_hidden_dim)\n",
        "    self.bilstm_a = LSTMModule(emb_dim,single_hidden_dim)\n",
        "    self.attention_mat = AttentionMatrix(single_hidden_dim*2)\n",
        "    self.h_pool = lambda t : self.horizontal_pooling(t)\n",
        "    self.v_pool = lambda t : self.vertical_pooling(t)\n",
        "    self.crit = nn.CosineEmbeddingLoss(margin=0.5)\n",
        "    self.decision_threshold = decision_threshold\n",
        "    self.tostring = {\"name\":\"ap_bilstm\",\"emb_dim\":emb_dim,\"hidden_dim\":single_hidden_dim*2}\n",
        "    \n",
        "  # Work in progress\n",
        "  def forward(self,q,a):\n",
        "    q_embed = self.emb(q)\n",
        "    a_embed = self.emb(a)\n",
        "    q_enc = self.bilstm_q(q_embed).transpose(1,2) #transposing in order to have (emb,lenght) for the attention matrix\n",
        "    a_enc = self.bilstm_a(a_embed).transpose(1,2)\n",
        "    mat = self.attention_mat(q_enc,a_enc)\n",
        "    # check attention mat dimensions\n",
        "    q_att = f.softmax(self.h_pool(mat),dim=1)\n",
        "    a_att = f.softmax(self.v_pool(mat),dim=1)\n",
        "    q = self.flatten(torch.matmul(q_enc,q_att))\n",
        "    a = self.flatten(torch.matmul(a_enc,a_att))\n",
        "    return q,a\n",
        "    \n",
        "  def flatten(self,x):\n",
        "    return x.view(x.size(0),-1)\n",
        "  \n",
        "  def horizontal_pooling(self,x):\n",
        "    return f.max_pool1d(x,x.size(2))\n",
        "  \n",
        "  def vertical_pooling(self,x):\n",
        "    return self.horizontal_pooling(x.transpose(1,2)) \n",
        "  \n",
        "  def compute_batch_stats(self,model_output,batch): # TO BE fixed\n",
        "    r_q,r_a = model_output\n",
        "    batch_loss = self.crit(r_q,r_a,batch.label.float()*2.0-1) # the loss wants -1|1 values, input values are 0|1\n",
        "    sim = f.cosine_similarity(r_q,r_a)\n",
        "    # compute the decision of the network\n",
        "    pred = sim.clone()\n",
        "    pred[sim > self.decision_threshold] = 1\n",
        "    pred[sim <= self.decision_threshold] = 0\n",
        "    correct_pred = (pred.squeeze() == batch.label.float()).sum().float()\n",
        "    return sim,batch_loss,correct_pred\n",
        "    \n",
        "  \n",
        "def test(model, data, mode='test'):\n",
        "    if mode == 'dev':\n",
        "        iterator = iter(data.dev_iter)\n",
        "    else:\n",
        "        iterator = iter(data.test_iter)\n",
        "    model.eval()\n",
        "    \n",
        "    correct_predictions, loss, number_of_samples = 0, 0, 0\n",
        "    for batch in iterator:\n",
        "        q,a = 'question', 'sentence'\n",
        "        q,a = getattr(batch, q), getattr(batch, a)\n",
        "        model_output = model(q,a)\n",
        "        \n",
        "        output, batch_loss, batch_correct_predictions = model.compute_batch_stats(model_output,\n",
        "                                                                                  batch)\n",
        "\n",
        "        correct_predictions += batch_correct_predictions\n",
        "        number_of_samples += len(output)\n",
        "        loss += batch_loss.item()\n",
        "    model.train()\n",
        "    acc = correct_predictions / number_of_samples\n",
        "    acc = acc.cpu().item()\n",
        "    return loss, acc\n",
        "  \n",
        "def tostring(model,batch_size):\n",
        "  s = model.tostring[\"name\"]\n",
        "  for key in model.tostring:\n",
        "    if key != \"name\":\n",
        "      s += \"_\"+key+str(model.tostring[key])\n",
        "  return s+\"_bs\"+str(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mo_x7Bnl5Sgg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1516
        },
        "outputId": "69ee7d58-a6de-4573-f659-1f58047e0128"
      },
      "cell_type": "code",
      "source": [
        "emb_dim = 300\n",
        "hidden_dim = 141# 4000\n",
        "context_window = 3\n",
        "batch_size = 20\n",
        "print_freq = 5\n",
        "\n",
        "from enum import Enum\n",
        "available_datasets = Enum(\"available_datasets\",\"wiki insurance\")\n",
        "chosen_ds = available_datasets.wiki\n",
        "wiki_base_dir = '/content/gdrive/My Drive/WikiQA/'\n",
        "insurance_base_dir ='/content/gdrive/My Drive/InsuranceQA/'\n",
        "\n",
        "if chosen_ds == available_datasets.wiki:\n",
        "  base_dir = wiki_base_dir\n",
        "  dataset = WikiQA_dataset(wiki_base_dir,emb_dim,batch_size)  \n",
        "elif chosen_ds == available_datasets.insurance:\n",
        "  base_dir = insurance_base_dir\n",
        "  dataset = InsuranceQA_dataset(insurance_base_dir,emb_dim,batch_size)\n",
        "\n",
        "\n",
        "dict_size = len(dataset.TEXT.vocab)\n",
        "\n",
        "# model = BaselineQACNN(emb_dim,dict_size,hidden_dim,context_window,dataset)\n",
        "# model = BaselineQAbiLSTM(emb_dim,dict_size,hidden_dim,dataset)\n",
        "# model = AP_CNN(emb_dim,dict_size,hidden_dim,context_window,dataset)\n",
        "model = AP_biLSTM(emb_dim,dict_size,hidden_dim,dataset)\n",
        "\n",
        "print(model)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(\"CUDA available\")\n",
        "  model = model.cuda()\n",
        "  \n",
        "learning_rate = 1.1\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate) # Adam\n",
        "loss = 0\n",
        "max_dev_acc, max_test_acc = 0, 0\n",
        "\n",
        "model.train()\n",
        "  \n",
        "for i,batch in enumerate(dataset.train_iter):\n",
        "  q,a = getattr(batch,'question'),getattr(batch,'sentence')\n",
        "  optimizer.zero_grad()\n",
        "  res = model(q,a)\n",
        "  out,batch_loss,correct_predictions = model.compute_batch_stats(res,batch)\n",
        "\n",
        "  loss += batch_loss.item()\n",
        "  batch_loss.backward()\n",
        "  optimizer.step()\n",
        "  if (i + 1) % print_freq == 0:\n",
        "    dev_loss, dev_acc = test(model,dataset, mode='dev')\n",
        "    test_loss, test_acc = test(model,dataset)\n",
        "    c = (i + 1) // print_freq\n",
        "    print('[INFO] train loss: {:.2f} / dev loss: {:.2f} / test loss: {:.2f}'\n",
        "          ' / dev acc: {:.2f} / test acc: {:.2f}'.format(loss, dev_loss,\n",
        "                                                         test_loss,\n",
        "                                                         dev_acc * 100,\n",
        "                                                         test_acc * 100))\n",
        "    '''\n",
        "    if dev_acc > max_dev_acc:\n",
        "          max_dev_acc = dev_acc\n",
        "          max_test_acc = test_acc\n",
        "          torch.save(model.state_dict(),base_dir+tostring(model,batch_size)+'.pt')\n",
        "          with open(base_dir+'perf.dat','w') as file:\n",
        "            file.write('train loss: {:.2f} / dev loss: {:.2f} / test loss: {:.2f}'\n",
        "                      ' / dev acc: {:.2f} / test acc: {:.2f}'.format(loss, dev_loss,\n",
        "                                                         test_loss,\n",
        "                                                         dev_acc * 100,\n",
        "                                                         test_acc * 100))\n",
        "    '''\n",
        "    loss = 0\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AP_biLSTM(\n",
            "  (emb): GloVeEmb(\n",
            "    (emb): Embedding(63328, 300)\n",
            "  )\n",
            "  (bilstm_q): LSTMModule(\n",
            "    (bilstm): LSTM(300, 141, bidirectional=True)\n",
            "  )\n",
            "  (bilstm_a): LSTMModule(\n",
            "    (bilstm): LSTM(300, 141, bidirectional=True)\n",
            "  )\n",
            "  (attention_mat): AttentionMatrix()\n",
            "  (crit): CosineEmbeddingLoss()\n",
            ")\n",
            "CUDA available\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  return Variable(arr, volatile=not train)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] train loss: 0.31 / dev loss: 5.66 / test loss: 11.46 / dev acc: 94.33 / test acc: 94.69\n",
            "[INFO] train loss: 0.21 / dev loss: 5.42 / test loss: 11.21 / dev acc: 93.64 / test acc: 92.74\n",
            "[INFO] train loss: 0.18 / dev loss: 5.51 / test loss: 11.47 / dev acc: 93.93 / test acc: 93.05\n",
            "[INFO] train loss: 0.26 / dev loss: 5.46 / test loss: 11.42 / dev acc: 93.49 / test acc: 92.37\n",
            "[INFO] train loss: 0.13 / dev loss: 5.33 / test loss: 11.31 / dev acc: 93.53 / test acc: 91.99\n",
            "[INFO] train loss: 0.17 / dev loss: 5.35 / test loss: 11.30 / dev acc: 94.00 / test acc: 92.95\n",
            "[INFO] train loss: 0.26 / dev loss: 5.36 / test loss: 11.32 / dev acc: 94.44 / test acc: 93.98\n",
            "[INFO] train loss: 0.28 / dev loss: 5.12 / test loss: 10.76 / dev acc: 93.34 / test acc: 92.51\n",
            "[INFO] train loss: 0.07 / dev loss: 5.05 / test loss: 10.82 / dev acc: 93.05 / test acc: 91.68\n",
            "[INFO] train loss: 0.19 / dev loss: 5.08 / test loss: 10.76 / dev acc: 92.87 / test acc: 92.23\n",
            "[INFO] train loss: 0.13 / dev loss: 5.17 / test loss: 10.86 / dev acc: 92.98 / test acc: 92.20\n",
            "[INFO] train loss: 0.29 / dev loss: 5.21 / test loss: 10.88 / dev acc: 93.01 / test acc: 92.38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-06354134b270>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mdev_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dev'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     print('[INFO] train loss: {:.2f} / dev loss: {:.2f} / test loss: {:.2f}'\n",
            "\u001b[0;32m<ipython-input-46-686f7d2012f8>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, data, mode)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'question'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sentence'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         output, batch_loss, batch_correct_predictions = model.compute_batch_stats(model_output,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-686f7d2012f8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, q, a)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0mq_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0ma_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m     \u001b[0mq_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbilstm_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#transposing in order to have (emb,lenght) for the attention matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     \u001b[0ma_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbilstm_a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_enc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-686f7d2012f8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_embed)\u001b[0m\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;31m# LSTM returns a tuple, the tensor is the first element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbilstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m                     \u001b[0;34m\"forward hooks should never return any values, but '{}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                     \"didn't return None\".format(hook))\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_hooks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m             \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "lv6iztrucbqC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "*Draft snippets*\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "nruHT8fI7P62",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "l = list(wiki_dataset.train.label)[1:]\n",
        "l = [int(_) for _ in l]\n",
        "import numpy as np\n",
        "np.sum(l)\n",
        "len(l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tL65x3a9W2sm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision import datasets,transforms\n",
        "data = datasets.MNIST('.',train=True,download=True,transform= transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tW2X_1v7Qg5n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('net.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "61vPsTfwvbhy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class uq(nn.Module):\n",
        "  def __init__(self,dim):\n",
        "    super(uq,self).__init__()\n",
        "    self.dim = dim\n",
        "    \n",
        "  def forward(self,x):\n",
        "    return x.unsqueeze(dim=self.dim)\n",
        "  \n",
        "  \n",
        "model = nn.Sequential(uq(1),nn.Conv2d(1,1,(2,3)))\n",
        "import numpy as np\n",
        "\n",
        "x = torch.from_numpy(np.random.randint(20,size=(30,2,3))).float()\n",
        "model(x).size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XKlyHQeFxUau",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "376fca47-6ec8-48b9-dce2-e126bd60106f"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "q = torch.from_numpy(np.random.randint(20,size=(30,4,5))).type(torch.FloatTensor)\n",
        "u = torch.Tensor(5,5).type(torch.FloatTensor)\n",
        "a = torch.from_numpy(np.random.randint(20,size=(30,5,9))).type(torch.FloatTensor)\n",
        "\n",
        "torch.matmul(torch.matmul(q,u),a).size()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30, 4, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "T6y8mVhrixhR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "70c0c1ba-cf29-4e97-d135-1ff4c9ea0020"
      },
      "cell_type": "code",
      "source": [
        "nn.Parameter(torch.Tensor(emb_dim,emb_dim).type(torch.FloatTensor),requires_grad=True)\n",
        "torch.from_numpy(np.zeros((3,3))).type(torch.FloatTensor)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}